{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITqu9v5IAsVY"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j8xckPcAsVb"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2rnQt-GAsVb"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oTXu_G7AsVb"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A8YRhDOUAsVc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Skip restarting message in Colab\n",
        "import sys; modules = list(sys.modules.keys())\n",
        "for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "\n",
        "!pip install unsloth vllm\n",
        "!pip install --upgrade pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mexRjcNAsVd"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1zyu9Ug2XEt"
      },
      "source": [
        "Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "45ea1505-daee-414b-afb3-59a4a3c9d37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 02-15 20:07:51 __init__.py:190] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8-SLRUB2gwM"
      },
      "source": [
        "Load up `Llama 3.1 8B Instruct`, and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "927cd3c4fa3c42a5b8a43b1cd76ac0fa",
            "3ecf7acd701046b09c3cc4eeaaf0d0da",
            "f49d0961633243c2b9a758069c95ef89",
            "c476ee6ef613434d8b0cc4f24ddc2783",
            "26f99e3a5d8c4c059bcbd8f36ae268ba",
            "6d1a54b481de4831b67bbbd8341f24f4",
            "7fa8d1dfb3904cdf9bde8dc63beb0ad1",
            "220f9808516e44fe89d801f0c704e74a",
            "775c698ea42a49308f38e184c100f03f",
            "3fef938580614b9b8cb58e9775b4aad5",
            "ad934d01cd09482cbb14b36699e47061",
            "71b272f2bccf4722a294d23990b531b7",
            "1be4534934324b93803f8160e3b8e41a",
            "921d7eb4bfe44bfbbfa7e8a25bec1c0c",
            "a8155966aa3446bdae206cf7b32ae49c",
            "b6a168eae0db4167a51cefd51da18bde",
            "af9915c4923e4cacbc2fb34d7ea176c1",
            "32d4e2af687f4417bdd1b0803f136d41",
            "a5b01e422d794819a62f1c816f58f032",
            "398c0b403e6d4a4bbe3a13647ccec10c",
            "0bf3c67f0d7d4800b60ddce7e93657bd",
            "82dd273abe30413c837bcaed8c3cf03b"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "68491d27-5f22-4b1f-d948-bd54832bb592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit with actual GPU utilization = 59.59%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 7.69 GB. Also swap space = 2 GB.\n",
            "WARNING 02-15 20:08:05 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-15 20:08:29 config.py:542] This model supports multiple tasks: {'classify', 'score', 'generate', 'reward', 'embed'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.1.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 02-15 20:08:29 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=512, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n",
            "INFO 02-15 20:08:31 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-15 20:08:31 cuda.py:227] Using XFormers backend.\n",
            "INFO 02-15 20:08:32 model_runner.py:1110] Starting to load model unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit...\n",
            "INFO 02-15 20:08:33 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-15 20:08:34 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "927cd3c4fa3c42a5b8a43b1cd76ac0fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71b272f2bccf4722a294d23990b531b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-15 20:08:36 model_runner.py:1115] Loading model weights took 1.0453 GB\n",
            "INFO 02-15 20:08:36 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 02-15 20:08:41 worker.py:267] Memory profiling takes 3.56 seconds\n",
            "INFO 02-15 20:08:41 worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.60) = 8.78GiB\n",
            "INFO 02-15 20:08:41 worker.py:267] model weights take 1.05GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 0.89GiB; the rest of the memory reserved for KV Cache is 6.80GiB.\n",
            "INFO 02-15 20:08:41 executor_base.py:110] # CUDA blocks: 13932, # CPU blocks: 4096\n",
            "INFO 02-15 20:08:41 executor_base.py:115] Maximum concurrency for 512 tokens per request: 435.38x\n",
            "INFO 02-15 20:08:43 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:32<00:00,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-15 20:09:15 model_runner.py:1562] Graph capturing finished in 33 secs, took 0.35 GiB\n",
            "INFO 02-15 20:09:15 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 38.79 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Unsloth 2025.2.12 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 512 # Can increase for longer reasoning traces\n",
        "lora_rank = 32 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-1B-Instruct-unsloth-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We directly leverage [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) for data prep and all reward functions. You are free to create your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cXk993X6C2ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884c6548-409c-436b-d98e-d4edad3e9ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': '72', 'prompt': [{'content': '\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n...\\n</answer>\\n', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]}\n",
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': x['question']}\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer'])\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "print(dataset[0])\n",
        "\n",
        "print(type(dataset))\n",
        "\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reasoning_gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUO7_nrkFQsG",
        "outputId": "1b2092e4-3440-41d2-ad9c-003aee178018"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reasoning_gym in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
            "Requirement already satisfied: arckit==0.1.0 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (0.1.0)\n",
            "Requirement already satisfied: bfi==1.0.4 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (1.0.4)\n",
            "Requirement already satisfied: cellpylib==2.4.0 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (2.4.0)\n",
            "Requirement already satisfied: magiccube==0.3.0 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (0.3.0)\n",
            "Requirement already satisfied: pycosat==0.6.6 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (0.6.6)\n",
            "Requirement already satisfied: pyfiglet==1.0.2 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2024.1 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (2025.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (6.0.2)\n",
            "Requirement already satisfied: sympy>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (1.13.1)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from reasoning_gym) (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from arckit==0.1.0->reasoning_gym) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from arckit==0.1.0->reasoning_gym) (13.9.4)\n",
            "Requirement already satisfied: drawsvg in /usr/local/lib/python3.11/dist-packages (from arckit==0.1.0->reasoning_gym) (2.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from cellpylib==2.4.0->reasoning_gym) (3.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.1->reasoning_gym) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->arckit==0.1.0->reasoning_gym) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->arckit==0.1.0->reasoning_gym) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->arckit==0.1.0->reasoning_gym) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.2->cellpylib==2.4.0->reasoning_gym) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "import reasoning_gym  # Assuming you have this library installed\n",
        "\n",
        "# Load and prep dataset (modified for ReasoningGymDataset)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "def convert_list_to_dataset(data):\n",
        "    \"\"\"Converts a list of dictionaries to a Hugging Face Dataset.\"\"\"\n",
        "\n",
        "    # Check if the data is a list of dictionaries\n",
        "    if not isinstance(data, list) or not all(isinstance(item, dict) for item in data):\n",
        "        raise TypeError(\"Input data must be a list of dictionaries.\")\n",
        "\n",
        "    # Create the Dataset\n",
        "    dataset = Dataset.from_list(data)\n",
        "    return dataset\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_geometry_questions():\n",
        "    data = reasoning_gym.create_dataset('advanced_geometry', size=1000, seed=42)\n",
        "    def transform_item(x):\n",
        "      return {\n",
        "          'prompt': [\n",
        "              {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "              {'role': 'user', 'content': x['question']}\n",
        "          ],\n",
        "          'answer': x['answer']\n",
        "      }\n",
        "\n",
        "    data = list(map(transform_item, data))\n",
        "\n",
        "    return data\n",
        "\n",
        "dataset = get_geometry_questions()\n",
        "\n",
        "dataset = convert_list_to_dataset(dataset)\n",
        "\n",
        "print(dataset[0])\n",
        "\n",
        "print(type(dataset))\n",
        "# Reward functions (modified to work with ReasoningGymDataset)\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUE37sNBCinQ",
        "outputId": "60fb659c-62a1-403b-a92e-2c9c1bbc6e8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': [{'content': '\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n...\\n</answer>\\n', 'role': 'system'}, {'content': 'In triangle ABC with coordinates A=(-7, -10), B=(-2, -3), and C=(-3, -6), find the measure (in degrees) of angle ABC.', 'role': 'user'}], 'answer': '17.10¬∞'}\n",
            "<class 'datasets.arrow_dataset.Dataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux6iqP7z5YOo"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "1015f323-1174-4a69-b49f-a6f54d35a179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We know expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 6\n"
          ]
        }
      ],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 6, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 200,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 250,\n",
        "    save_steps = 250,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "29b09a19-b1a9-41e3-cfe2-4b249fa2d589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 6 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 6 | Total steps = 250\n",
            " \"-____-\"     Number of trainable parameters = 22,544,384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Question:\n",
            "Given a triangle with vertices A=(-1, 10), B=(1, -3), C=(10, 0), determine the angle at B in degrees. \n",
            "Answer:\n",
            "80.31¬∞ \n",
            "Response:\n",
            "To determine the angle at B in degrees, I'll use the Law of Cosines to find the angle:\n",
            "\n",
            "```python\n",
            "import math\n",
            "\n",
            "# Define the coordinates of the vertices\n",
            "A = (-1, 10)\n",
            "B = (1, -3)\n",
            "C = (10, 0)\n",
            "\n",
            "# Calculate the lengths of the sides of the triangle\n",
            "AB = math.sqrt((B[0] - A[0])**2 + (B[1] - A[1])**2)\n",
            "AC = math.sqrt((B[0] - A[0])**2 + (B[1] - A[1])**2)\n",
            "BC = math.sqrt((B[0] - C[0])**2 + (B[1] - C[1])**2)\n",
            "\n",
            "# Use the Law of Cosines to find the angle B\n",
            "cos_B = (AB**2 + AC**2 - BC**2) / (2 * AB * AC)\n",
            "B_angle = math.degrees(math.ac \n",
            "Extracted:\n",
            "To determine the angle at B in degrees, I'll use the Law of Cosines to find the angle:\n",
            "\n",
            "```python\n",
            "import math\n",
            "\n",
            "# Define the coordinates of the vertices\n",
            "A = (-1, 10)\n",
            "B = (1, -3)\n",
            "C = (10, 0)\n",
            "\n",
            "# Calculate the lengths of the sides of the triangle\n",
            "AB = math.sqrt((B[0] - A[0])**2 + (B[1] - A[1])**2)\n",
            "AC = math.sqrt((B[0] - A[0])**2 + (B[1] - A[1])**2)\n",
            "BC = math.sqrt((B[0] - C[0])**2 + (B[1] - C[1])**2)\n",
            "\n",
            "# Use the Law of Cosines to find the angle B\n",
            "cos_B = (AB**2 + AC**2 - BC**2) / (2 * AB * AC)\n",
            "B_angle = math.degrees(math.ac\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 11/250 01:25 < 38:00, 0.10 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / xmlcount_reward_func</th>\n",
              "      <th>rewards / soft_format_reward_func</th>\n",
              "      <th>rewards / strict_format_reward_func</th>\n",
              "      <th>rewards / int_reward_func</th>\n",
              "      <th>rewards / correctness_reward_func</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.666672</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Question:\n",
            "Given a triangle with vertices A=(-7, -1), B=(-6, 8), C=(10, 9), determine the angle at B in degrees. \n",
            "Answer:\n",
            "99.92¬∞ \n",
            "Response:\n",
            "## Step 1: Calculate the lengths of the sides of the triangle\n",
            "To find the angle at B, we first need to find the lengths of the sides of the triangle. We can use the distance formula to calculate the lengths of AB, BC, and AC. The distance formula is given by:\n",
            "\\[ d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} \\]\n",
            "For AB: \n",
            "\\[ AB = \\sqrt{(-6 - (-7))^2 + (8 - (-1))^2} = \\sqrt{(1)^2 + (9)^2} = \\sqrt{1 + 81} = \\sqrt{82} \\]\n",
            "For BC:\n",
            "\\[ BC = \\sqrt{(10 - (-6))^2 + (9 - 8)^2} = \\sqrt{(16)^2 + (1)^2} = \\sqrt{256 + 1} = \\sqrt{257} \\]\n",
            " \n",
            "Extracted:\n",
            "## Step 1: Calculate the lengths of the sides of the triangle\n",
            "To find the angle at B, we first need to find the lengths of the sides of the triangle. We can use the distance formula to calculate the lengths of AB, BC, and AC. The distance formula is given by:\n",
            "\\[ d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} \\]\n",
            "For AB: \n",
            "\\[ AB = \\sqrt{(-6 - (-7))^2 + (8 - (-1))^2} = \\sqrt{(1)^2 + (9)^2} = \\sqrt{1 + 81} = \\sqrt{82} \\]\n",
            "For BC:\n",
            "\\[ BC = \\sqrt{(10 - (-6))^2 + (9 - 8)^2} = \\sqrt{(16)^2 + (1)^2} = \\sqrt{256 + 1} = \\sqrt{257} \\]\n",
            "-------------------- Question:\n",
            "Given a triangle with vertices A=(5, 8), B=(-5, 5), C=(-2, 4), determine the angle at B in degrees. \n",
            "Answer:\n",
            "35.13¬∞ \n",
            "Response:\n",
            "To determine the angle at B in degrees, we need to use the Law of Cosines which is a part of the Law of Cosines formula, which in turn relates the lengths of the sides of a triangle to the cosine of its angles.\n",
            "\n",
            "Here's the step-by-step process:\n",
            "\n",
            "- Find the length of side AB: The distance between points A (5, 8) and B (-5, 5) is calculated as follows:\n",
            "  First, the distance between points A or B is given by:\n",
            "  distance = ‚àö((x2-x1)^2 + (y2-y1)^2) \n",
            "  distance_AB = ‚àö((-5-5)^2 + (5-8)^2) = ‚àö((-10)^2 + (-3)^2) = ‚àö(100 + 9) = ‚àö109 \n",
            "\n",
            "Using the inverse cosine function, we find the angle: cos(A) = AB / 2AC\n",
            "\n",
            "Here AB is the square root of 109: 10 \n",
            "Extracted:\n",
            "To determine the angle at B in degrees, we need to use the Law of Cosines which is a part of the Law of Cosines formula, which in turn relates the lengths of the sides of a triangle to the cosine of its angles.\n",
            "\n",
            "Here's the step-by-step process:\n",
            "\n",
            "- Find the length of side AB: The distance between points A (5, 8) and B (-5, 5) is calculated as follows:\n",
            "  First, the distance between points A or B is given by:\n",
            "  distance = ‚àö((x2-x1)^2 + (y2-y1)^2) \n",
            "  distance_AB = ‚àö((-5-5)^2 + (5-8)^2) = ‚àö((-10)^2 + (-3)^2) = ‚àö(100 + 9) = ‚àö109 \n",
            "\n",
            "Using the inverse cosine function, we find the angle: cos(A) = AB / 2AC\n",
            "\n",
            "Here AB is the square root of 109: 10\n",
            "-------------------- Question:\n",
            "For triangle with vertices A=(7, -4), B=(-6, 7), and C=(1, -5), determine the orthocenter (intersection of altitudes). \n",
            "Answer:\n",
            "(-3.177, -9.937) \n",
            "Response:\n",
            "To find the orthocenter of the triangle with vertices A=(7, -4), B=(-6, 7), and C=(1, -5), we need to find the intersection of its altitudes.\n",
            "\n",
            "Since the given vertices lie on a plane, we can find the midpoint of any side. Let's find the midpoint of AB:\n",
            "\n",
            "Midpoint = ((7-6)/2, (-4+7)/2)\n",
            "= (1/2, 1/2)\n",
            "\n",
            "Now, we can find the slope of the altitude from vertex A to vertex C:\n",
            "\n",
            "m = (-5 - (-4))/(1 - 7)\n",
            "= 1/6\n",
            "\n",
            "Now we can find the slope of the altitude from vertex B to vertex C:\n",
            "\n",
            "m = (-5 - 7)/(1 - (-6))\n",
            "= -12/7\n",
            "\n",
            "Now we can find the equation of these two altitudes:\n",
            "\n",
            "Equation of altitude from A = y - 1/2 = 1/6(x \n",
            "Extracted:\n",
            "To find the orthocenter of the triangle with vertices A=(7, -4), B=(-6, 7), and C=(1, -5), we need to find the intersection of its altitudes.\n",
            "\n",
            "Since the given vertices lie on a plane, we can find the midpoint of any side. Let's find the midpoint of AB:\n",
            "\n",
            "Midpoint = ((7-6)/2, (-4+7)/2)\n",
            "= (1/2, 1/2)\n",
            "\n",
            "Now, we can find the slope of the altitude from vertex A to vertex C:\n",
            "\n",
            "m = (-5 - (-4))/(1 - 7)\n",
            "= 1/6\n",
            "\n",
            "Now we can find the slope of the altitude from vertex B to vertex C:\n",
            "\n",
            "m = (-5 - 7)/(1 - (-6))\n",
            "= -12/7\n",
            "\n",
            "Now we can find the equation of these two altitudes:\n",
            "\n",
            "Equation of altitude from A = y - 1/2 = 1/6(x\n",
            "-------------------- Question:\n",
            "Given a triangle with vertices A=(5, -3), B=(-5, -10), C=(-10, 1), determine the angle at B in degrees. \n",
            "Answer:\n",
            "79.45¬∞ \n",
            "Response:\n",
            "To find the angle A at B in the triangle, we will use the Law of Cosines, which is used to calculate the length of a side of a triangle.\n",
            "\n",
            "We can calculate the distance between points B = (5, -10) and A = (-5, -3) using the distance formula:\n",
            "\n",
            "   distance = sqrt((x2 - x1)^2 + (y2 - y1)^2) \n",
            "   distance = sqrt((5-(-5))^2 + (-10 -(-3))^2)\n",
            "   distance = sqrt((10)^2 + (-7)^2) \n",
            "   distance = sqrt(100 + 49)\n",
            "   distance = sqrt(149)\n",
            "\n",
            "The Law of Cosines for an angle A opposite side <b>AB</b> in triangle ABC can be written as:\n",
            "\n",
            "cos(A) = (b^2 + c^2 - a^2) / (2bc) \n",
            "\n",
            "In this case:\n",
            "\n",
            "a = sqrt(149), b = sqrt \n",
            "Extracted:\n",
            "To find the angle A at B in the triangle, we will use the Law of Cosines, which is used to calculate the length of a side of a triangle.\n",
            "\n",
            "We can calculate the distance between points B = (5, -10) and A = (-5, -3) using the distance formula:\n",
            "\n",
            "   distance = sqrt((x2 - x1)^2 + (y2 - y1)^2) \n",
            "   distance = sqrt((5-(-5))^2 + (-10 -(-3))^2)\n",
            "   distance = sqrt((10)^2 + (-7)^2) \n",
            "   distance = sqrt(100 + 49)\n",
            "   distance = sqrt(149)\n",
            "\n",
            "The Law of Cosines for an angle A opposite side <b>AB</b> in triangle ABC can be written as:\n",
            "\n",
            "cos(A) = (b^2 + c^2 - a^2) / (2bc) \n",
            "\n",
            "In this case:\n",
            "\n",
            "a = sqrt(149), b = sqrt\n",
            "-------------------- Question:\n",
            "Given triangle ABC with coordinates A=(9, 10), B=(0, 6), and C=(7, 4), find the coordinates of its orthocenter. \n",
            "Answer:\n",
            "(7.174, 3.609) \n",
            "Response:\n",
            "## Step 1: To find the orthocenter of triangle ABC, we first need to find the slope of the altitude from point A to line BC.\n",
            "To find the slope of the line containing BC, we use the slope formula: \n",
            "\\[ m = \\frac{y_2 - y_1}{x_2 - x_1} \n",
            "Given B=(0,6) and C=(7,4), substituting the values we get:\n",
            "\\[ m = \\frac{4-6}{7-0} \n",
            "m = \\frac{-2}{7} \n",
            "\n",
            "## Step 2: The slope of the altitude from A to BC is the negative reciprocal of this slope.\n",
            "Therefore, the slope of the altitude from A to BC is 7/2.\n",
            "\n",
            "## Step 3: Now we can use the point-slope formula to find the equation of the altitude from A to BC.\n",
            "The equation of the altitude from point A=(9,10) can be expressed as \n",
            "Extracted:\n",
            "## Step 1: To find the orthocenter of triangle ABC, we first need to find the slope of the altitude from point A to line BC.\n",
            "To find the slope of the line containing BC, we use the slope formula: \n",
            "\\[ m = \\frac{y_2 - y_1}{x_2 - x_1} \n",
            "Given B=(0,6) and C=(7,4), substituting the values we get:\n",
            "\\[ m = \\frac{4-6}{7-0} \n",
            "m = \\frac{-2}{7} \n",
            "\n",
            "## Step 2: The slope of the altitude from A to BC is the negative reciprocal of this slope.\n",
            "Therefore, the slope of the altitude from A to BC is 7/2.\n",
            "\n",
            "## Step 3: Now we can use the point-slope formula to find the equation of the altitude from A to BC.\n",
            "The equation of the altitude from point A=(9,10) can be expressed as\n",
            "-------------------- Question:\n",
            "Find the incircle radius of triangle ABC whose vertices are A=(1, -8), B=(10, 5), and C=(0, 1). \n",
            "Answer:\n",
            "2.638 \n",
            "Response:\n",
            "To find the incircle of a triangle, we need to find the radius of the incircle. The formula for the radius of the incircle is given by:\n",
            "\n",
            "r = \\frac{b \\cdot A}{p}\n",
            "\n",
            "where r is the radius of the incircle, b is the semiperimeter of the triangle, and p is the perimeter of the triangle.\n",
            "\n",
            "To find the semiperimeter (s) of triangle ABC, we can use Heron's formula:\n",
            "\n",
            "s = \\sqrt{(a + b + c)/2}\n",
            "\n",
            "Here, a, b, and c are the side lengths of the triangle.\n",
            "\n",
            "Using the distance formula, we can find the side lengths of the triangle as follows:\n",
            "\n",
            "a = ‚àö((x2 - x1)^2 + (y2 - y1)^2)\n",
            "= ‚àö((10-1)^2 + (5-(-8))^2)\n",
            "= ‚àö(81 + 113)\n",
            "= ‚àö(194)\n",
            "\n",
            "b = ‚àö((0 - 10 \n",
            "Extracted:\n",
            "To find the incircle of a triangle, we need to find the radius of the incircle. The formula for the radius of the incircle is given by:\n",
            "\n",
            "r = \\frac{b \\cdot A}{p}\n",
            "\n",
            "where r is the radius of the incircle, b is the semiperimeter of the triangle, and p is the perimeter of the triangle.\n",
            "\n",
            "To find the semiperimeter (s) of triangle ABC, we can use Heron's formula:\n",
            "\n",
            "s = \\sqrt{(a + b + c)/2}\n",
            "\n",
            "Here, a, b, and c are the side lengths of the triangle.\n",
            "\n",
            "Using the distance formula, we can find the side lengths of the triangle as follows:\n",
            "\n",
            "a = ‚àö((x2 - x1)^2 + (y2 - y1)^2)\n",
            "= ‚àö((10-1)^2 + (5-(-8))^2)\n",
            "= ‚àö(81 + 113)\n",
            "= ‚àö(194)\n",
            "\n",
            "b = ‚àö((0 - 10\n",
            "-------------------- Question:\n",
            "Given triangle ABC with coordinates A=(-1, -8), B=(8, -5), and C=(0, -6), find the coordinates of its orthocenter. \n",
            "Answer:\n",
            "(-2.000, 0.000) \n",
            "Response:\n",
            "To find the orthocenter of the triangle, we first need to find the slopes of the sides of the triangle.\n",
            "\n",
            "Since we have the coordinates of the vertices, we can use the slope formula: m = (y2 - y1)/(x2 - x1) to find the slopes of the sides.\n",
            "\n",
            "The slope of AB = (-8 - (-5))/(1 - 8) = 3.\n",
            "\n",
            "The slope of AC = (-6 - (-8))/(0 - 1) = 2.\n",
            "\n",
            "The slope of BC = (-5 - (-6))/(8 - 0) = 1/4.\n",
            "\n",
            "Now, we can find the slopes of the altitudes of the triangle.\n",
            "\n",
            "The altitude from A to BC: m1 = (y - (-6))/(x - 0) = (y + 8)/x, since A has coordinates (-1, -8).\n",
            "\n",
            "The altitude from B to AC: m2 = (-5 - (-6))/(8 - 0 \n",
            "Extracted:\n",
            "To find the orthocenter of the triangle, we first need to find the slopes of the sides of the triangle.\n",
            "\n",
            "Since we have the coordinates of the vertices, we can use the slope formula: m = (y2 - y1)/(x2 - x1) to find the slopes of the sides.\n",
            "\n",
            "The slope of AB = (-8 - (-5))/(1 - 8) = 3.\n",
            "\n",
            "The slope of AC = (-6 - (-8))/(0 - 1) = 2.\n",
            "\n",
            "The slope of BC = (-5 - (-6))/(8 - 0) = 1/4.\n",
            "\n",
            "Now, we can find the slopes of the altitudes of the triangle.\n",
            "\n",
            "The altitude from A to BC: m1 = (y - (-6))/(x - 0) = (y + 8)/x, since A has coordinates (-1, -8).\n",
            "\n",
            "The altitude from B to AC: m2 = (-5 - (-6))/(8 - 0\n",
            "-------------------- Question:\n",
            "For triangle with vertices A=(7, -7), B=(4, -4), and C=(7, 2), determine the orthocenter (intersection of altitudes). \n",
            "Answer:\n",
            "(1.000, -4.000) \n",
            "Response:\n",
            "To find the orthocenter of a triangle, we need to find the intersection point of its altitudes. \n",
            "\n",
            "In this case, we'll use the formula for the altitude in a triangle, given points A, B, and C:\n",
            " \n",
            "First, we need to find the slopes of the sides AB, BC, and AC to get the equation of their respective altitudes.\n",
            " \n",
            "The slope of AB is given by:\n",
            " \n",
            "m_{AB} = \\frac{y_B - y_A}{x_B - x_A} = \\frac{-4 - (-7)}{4 - 7} = 3.\n",
            "\n",
            "The slope of BC is given by:\n",
            " \n",
            "m_{BC} = \\frac{y_C - y_B}{x_C - x_B} = \\frac{2 - (-4)}{7 - 4} = 2.\n",
            "\n",
            "\n",
            "The slope of AC is given by:\n",
            " \n",
            "m_{AC} = \\frac{y_C - y_A}{x_C - x \n",
            "Extracted:\n",
            "To find the orthocenter of a triangle, we need to find the intersection point of its altitudes. \n",
            "\n",
            "In this case, we'll use the formula for the altitude in a triangle, given points A, B, and C:\n",
            " \n",
            "First, we need to find the slopes of the sides AB, BC, and AC to get the equation of their respective altitudes.\n",
            " \n",
            "The slope of AB is given by:\n",
            " \n",
            "m_{AB} = \\frac{y_B - y_A}{x_B - x_A} = \\frac{-4 - (-7)}{4 - 7} = 3.\n",
            "\n",
            "The slope of BC is given by:\n",
            " \n",
            "m_{BC} = \\frac{y_C - y_B}{x_C - x_B} = \\frac{2 - (-4)}{7 - 4} = 2.\n",
            "\n",
            "\n",
            "The slope of AC is given by:\n",
            " \n",
            "m_{AC} = \\frac{y_C - y_A}{x_C - x\n",
            "-------------------- Question:\n",
            "Given a triangle with vertices A=(-1, 10), B=(-10, -5), C=(-8, 1), determine the angle at B in degrees. \n",
            "Answer:\n",
            "12.53¬∞ \n",
            "Response:\n",
            "To determine the angle at vertex B, we can use the Law of Cosines formula:\n",
            "\n",
            "cos(B) = (a^2 + c^2 - b^2) / (2 * ac)\n",
            "\n",
            "where a, b, and c are the sides of the triangle, and b is the other side. In this case, we have:\n",
            "\n",
            "a = AB = sqrt((-1 - (-10))^2 + (10 - (-5))^2) = sqrt(9^2 + 15^2) = sqrt(81 + 225) = sqrt(306)\n",
            "c = AC = sqrt((-8 - (-1))^2 + (1 - 10)^2) = sqrt(49 + 81) = sqrt(130)\n",
            "\n",
            "Now we can plug these values into the formula:\n",
            "\n",
            "cos(B) = (306 + 130 - 225) / (2 * sqrt(306) * sqrt(130))\n",
            "= (141 / (2 * sqrt(306) * sqrt(130 \n",
            "Extracted:\n",
            "To determine the angle at vertex B, we can use the Law of Cosines formula:\n",
            "\n",
            "cos(B) = (a^2 + c^2 - b^2) / (2 * ac)\n",
            "\n",
            "where a, b, and c are the sides of the triangle, and b is the other side. In this case, we have:\n",
            "\n",
            "a = AB = sqrt((-1 - (-10))^2 + (10 - (-5))^2) = sqrt(9^2 + 15^2) = sqrt(81 + 225) = sqrt(306)\n",
            "c = AC = sqrt((-8 - (-1))^2 + (1 - 10)^2) = sqrt(49 + 81) = sqrt(130)\n",
            "\n",
            "Now we can plug these values into the formula:\n",
            "\n",
            "cos(B) = (306 + 130 - 225) / (2 * sqrt(306) * sqrt(130))\n",
            "= (141 / (2 * sqrt(306) * sqrt(130\n"
          ]
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "qtcz_lpbVC92",
        "outputId": "9b12655a-7905-42a8-d6f0-210ff74a6d73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:23<00:00, 23.78s/it, est. speed input: 1.64 toks/s, output: 19.94 toks/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Calculating pi to a large number of decimal places is a complex task that requires a computational approach, rather than a simple mathematical formula. Here\\'s a way to calculate pi using the Monte Carlo method, which is an approximation method that uses random numbers to estimate the value of pi:\\n\\n**The Monte Carlo Method**\\n\\nThe Monte Carlo method is based on the idea of simulating the probability of a random walk across a square and circle. Here\\'s the basic idea:\\n\\n1. Draw a square and a circle on a piece of paper.\\n2. Generate random points within the square.\\n3. Count the proportion of points that fall within the circle.\\n4. The ratio of points within the circle to the total number of points is approximately equal to the ratio of the area of the circle to the area of the square, which is pi.\\n\\n**Mathematical Formulation**\\n\\nLet\\'s denote the following variables:\\n\\n*   `N`: the number of random points generated\\n*   `n`: the number of points within the circle\\n*   `pi_approx`: the approximated value of pi\\n\\nThe formula to calculate pi is:\\n\\n`pi_approx = (4 * n) / N`\\n\\n**Python Code**\\n\\nHere\\'s a simple Python code snippet to calculate pi using the Monte Carlo method:\\n\\n```python\\nimport random\\nimport math\\n\\ndef calculate_pi(num_points):\\n    # Generate random points within the square (-1, -1) to (1, 1)\\n    points_inside_circle = 0\\n    for _ in range(num_points):\\n        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\\n        # Check if the point falls within the circle (radius 1)\\n        if x**2 + y**2 <= 1:\\n            points_inside_circle += 1\\n\\n    # Calculate pi using the Monte Carlo method\\n    pi_approx = (4 * points_inside_circle) / num_points\\n    return pi_approx\\n\\nnum_points = 1000000\\npi_approx = calculate_pi(num_points)\\nprint(f\"Approximated pi: {pi_approx}\")\\nprint(f\"Difference between approximated pi and actual pi: {abs(pi_approx - math.pi)}\")\\n```\\n\\n**Note**: The more points you generate, the more accurate the approximation will be.\\n\\n**Limitations**\\n\\nThis method has a few limitations:\\n\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "zf_OY5WMVOxF",
        "outputId": "c34d81a7-192d-427d-81f0-cbca7009b7d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:23<00:00, 23.29s/it, est. speed input: 2.62 toks/s, output: 19.41 toks/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<reasoning>\\nPi (œÄ) is an irrational number that represents the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but its decimal representation goes on indefinitely without repeating.\\n\\nTo calculate pi, we can use various mathematical formulas and methods, such as the Leibniz formula, the Gregory-Leibniz series, or the Monte Carlo method. However, these methods are not practical for obtaining a high degree of accuracy.\\n\\nA more practical approach is to use the Bailey-Borwein-Plouffe (BBP) formula, which is a spigot algorithm that allows us to calculate any digit of pi without having to compute the preceding digits.\\n\\nAnother method is to use the Chudnovsky algorithm, which is a fast and efficient method for calculating pi to a high degree of accuracy.\\n\\nFor simplicity, we can use the first few terms of the BBP formula to estimate pi:\\nœÄ = 3 + 1/(4/3 - 1/(4/3 - 1/(4/3 - ...))\\n\\nLet's use this simplified formula to estimate pi:\\n\\nœÄ ‚âà 3 + 1/(4/3) ‚âà 3 + 1.3333 ‚âà 4.3333\\n\\nNow, let's add the next term:\\nœÄ ‚âà 4.3333 + 1/(4/3 - 1/(4/3)) ‚âà 4.3333 + 1/(1.3333 - 0.3333) ‚âà 4.3333 + 0.6667 ‚âà 5.0000\\n\\nNext term:\\nœÄ ‚âà 5.0000 + 1/(1.3333 - 1/(1.3333 - 1/(1.3333))) ‚âà 5.0000 + 1/(0.6667 - 0.3333) ‚âà 5.0000 + 0.3333 ‚âà 5.3333\\n\\nContinuing this process, we can obtain more accurate approximations of pi. However, for a more accurate answer, we would need to use a computer program or a calculator.\\n\\nA more precise calculation using a computer or calculator would give us a\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYaCM7ATAsVi"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "927cd3c4fa3c42a5b8a43b1cd76ac0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ecf7acd701046b09c3cc4eeaaf0d0da",
              "IPY_MODEL_f49d0961633243c2b9a758069c95ef89",
              "IPY_MODEL_c476ee6ef613434d8b0cc4f24ddc2783"
            ],
            "layout": "IPY_MODEL_26f99e3a5d8c4c059bcbd8f36ae268ba"
          }
        },
        "3ecf7acd701046b09c3cc4eeaaf0d0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1a54b481de4831b67bbbd8341f24f4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7fa8d1dfb3904cdf9bde8dc63beb0ad1",
            "value": ""
          }
        },
        "f49d0961633243c2b9a758069c95ef89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_220f9808516e44fe89d801f0c704e74a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_775c698ea42a49308f38e184c100f03f",
            "value": 1
          }
        },
        "c476ee6ef613434d8b0cc4f24ddc2783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fef938580614b9b8cb58e9775b4aad5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad934d01cd09482cbb14b36699e47061",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá1/1‚Äá[00:01&lt;00:00,‚Äá‚Äá1.12s/it]\n"
          }
        },
        "26f99e3a5d8c4c059bcbd8f36ae268ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1a54b481de4831b67bbbd8341f24f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa8d1dfb3904cdf9bde8dc63beb0ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "220f9808516e44fe89d801f0c704e74a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775c698ea42a49308f38e184c100f03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fef938580614b9b8cb58e9775b4aad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad934d01cd09482cbb14b36699e47061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71b272f2bccf4722a294d23990b531b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1be4534934324b93803f8160e3b8e41a",
              "IPY_MODEL_921d7eb4bfe44bfbbfa7e8a25bec1c0c",
              "IPY_MODEL_a8155966aa3446bdae206cf7b32ae49c"
            ],
            "layout": "IPY_MODEL_b6a168eae0db4167a51cefd51da18bde"
          }
        },
        "1be4534934324b93803f8160e3b8e41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9915c4923e4cacbc2fb34d7ea176c1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_32d4e2af687f4417bdd1b0803f136d41",
            "value": ""
          }
        },
        "921d7eb4bfe44bfbbfa7e8a25bec1c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b01e422d794819a62f1c816f58f032",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_398c0b403e6d4a4bbe3a13647ccec10c",
            "value": 1
          }
        },
        "a8155966aa3446bdae206cf7b32ae49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf3c67f0d7d4800b60ddce7e93657bd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_82dd273abe30413c837bcaed8c3cf03b",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá‚Äá1.40it/s]\n"
          }
        },
        "b6a168eae0db4167a51cefd51da18bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9915c4923e4cacbc2fb34d7ea176c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d4e2af687f4417bdd1b0803f136d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b01e422d794819a62f1c816f58f032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "398c0b403e6d4a4bbe3a13647ccec10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bf3c67f0d7d4800b60ddce7e93657bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82dd273abe30413c837bcaed8c3cf03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}